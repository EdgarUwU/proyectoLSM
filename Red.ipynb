{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Importamos las fotos tomadas-----------------------------\n",
    "from tensorflow.python.keras import optimizers         #Optimizador con el que vamos a entrenar el modelo\n",
    "from tensorflow.python.keras.models import Sequential  #Nos permite hacer redes neuronales secuenciales\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D  #Capas para hacer las convoluciones\n",
    "from tensorflow.python.keras import backend as K       #Si hay una sesion de keras, lo cerramos para tener todo limpio\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() #Limpiamos todo\n",
    "\n",
    "datos_entrenamiento = ''\n",
    "datos_validacion = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteraciones = 20 #Número de iteraciones para ajustar nuestro modelo\n",
    "altura, longitud = 200, 200 #Tamaño de la imágenes de entrenamiento\n",
    "batch_size = 1 # Número de imagenes que vamos a enviar\n",
    "pasos = 300/1  #Número de veces que se va a procesar la información en cada iteración\n",
    "pasos_validacion = 300/1  #Después de cada iteración, validamos lo anterior\n",
    "filtrosconv1 = 32\n",
    "filtrosconv2 = 64     #Numero de filtros que vamos a aplicar en cada convolucion\n",
    "filtrosconv3 = 128\n",
    "tam_filtro1 = (4,4)\n",
    "tam_filtro2 = (3,3)\n",
    "tam_filtro3 = (2,2)   #Tamaños de los filtros 1 y 2\n",
    "tam_pool = (2,2)  #Tamaño del filtro en max pooling\n",
    "clases = 5  #5 letras - Cambiar si se agrega más letras\n",
    "lr = 0.0005  #ajustes de la red neuronal para acercarse a una solucion optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Procesamiento de las imagenes\n",
    "preprocesamiento_entre = ImageDataGenerator(\n",
    "    rescale= 1./255,   #Pasar los pixeles de 0 a 255 | 0 a 1\n",
    "    shear_range = 0.3, #Generar nuestras imagenes inclinadas para un  mejor entrenamiento\n",
    "    zoom_range = 0.3,  #Genera imagenes con zoom para un mejor entrenamiento\n",
    "    horizontal_flip=True #Invierte las imagenes para mejor entrenamiento\n",
    ")\n",
    "\n",
    "preprocesamiento_vali = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "imagen_entreno = preprocesamiento_entre.flow_from_directory(\n",
    "    datos_entrenamiento,       #Va a tomar las fotos que ya almacenamos\n",
    "    target_size = (altura, longitud),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',  #Clasificacion categorica = por clases\n",
    ")\n",
    "\n",
    "imagen_validacion = preprocesamiento_vali.flow_from_directory(\n",
    "    datos_validacion,\n",
    "    target_size=(altura,longitud),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la red neuronal convolucional (CNN)\n",
    "cnn = Sequential()  #Red neuronal secuencial\n",
    "#Agregamos filtros con el fin de volver nuestra imagen muy profunda pero pequeña\n",
    "cnn.add(Convolution2D(filtrosconv1, tam_filtro1, padding = 'same', input_shape=(altura,longitud,3), activation = 'relu')) #Agregamos la primera capa\n",
    "         #Es una convolucion y realizamos config\n",
    "cnn.add(MaxPooling2D(pool_size=tam_pool)) #Despues de la primera capa vamos a tener una capa de max pooling y asignamos el tamaño\n",
    "\n",
    "cnn.add(Convolution2D(filtrosconv2, tam_filtro2, padding = 'same', activation='relu')) #Agregamos nueva capa\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tam_pool))\n",
    "\n",
    "#Nueva capa\n",
    "cnn.add(Convolution2D(filtrosconv3, tam_filtro3, padding= 'same', activation='relu')) #Agregamos nueva capa\n",
    "cnn.add(MaxPooling2D(pool_size=tam_pool))\n",
    "\n",
    "#Ahora vamos a convertir esa imagen profunda a una plana, para tener 1 dimension con toda la info\n",
    "cnn.add(Flatten())  #Aplanamos la imagen\n",
    "cnn.add(Dense(640 ,activation='relu'))  #Asignamos 426 neuronas\n",
    "cnn.add(Dropout(0.5)) #Apagamos el 50% de las neuronas en la funcion anterior para no sobreajustar la red\n",
    "cnn.add(Dense(clases, activation='softmax'))  #Es nuestra ultima capa, es la que nos dice la probabilidad de que sea alguna de las clases\n",
    "\n",
    "#Agregamos parametros para optimizar el modelo\n",
    "#Durante el entrenamiento tenga una autoevalucion, que se optimice con Adam, y la metrica sera accuracy\n",
    "# optimizar = tensorflow.keras.optimizers.Adam(learning_rate= lr)\n",
    "optimizar = optimizers.adam_v2.Adam(learning_rate= lr)\n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer= optimizar, metrics=['accuracy'])\n",
    "\n",
    "#Entrenaremos nuestra red\n",
    "cnn.fit(imagen_entreno, steps_per_epoch=pasos, epochs= iteraciones, validation_data= imagen_validacion, validation_steps=pasos_validacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el modelo\n",
    "cnn.save('ModeloLetras.h5')\n",
    "cnn.save_weights('PesosLetras.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd6de60cc202df302348488ddc539a0b871575196ba754f9909c09dd4d1cd470"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
